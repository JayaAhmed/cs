# -*- coding: utf-8 -*-
"""cs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VMcnvV5L1x5doivpDflI8CS2xc0BcJFY
"""

import re
import sys
from sklearn.metrics import confusion_matrix
import time
import datetime

import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn import metrics
from sklearn import preprocessing
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from google.colab import files

# Loading the data
uploaded = files.upload()

df = pd.read_csv('hygdata_v3.csv')

df.head()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
sns.set(style='darkgrid')
sns.set_palette('PuBuGn_d')

df.isnull().sum()
plt.figure(figsize=(14, 10))
sns.heatmap(df.isnull(), cmap='viridis')
df.isnull().any()

df.shape

print(list(df.columns))

df.dtypes.sort_values().to_frame('feature_type').groupby(by = 'feature_type').size().to_frame('count').reset_index()

#Finding missing columns and their types

df_dtypes = pd.merge(df.isnull().sum(axis = 0).sort_values().to_frame('missing_value').reset_index(),
                     df.dtypes.to_frame('feature_type').reset_index(),
                     on = 'index',
                     how = 'inner')

df_dtypes.sort_values(['missing_value', 'feature_type'])

#Check columns have more than 110000 missing values

missing_df = df.isnull().sum(axis = 0).sort_values().to_frame('missing_value').reset_index()

miss_11 = list(missing_df[missing_df.missing_value >= 110000]['index'])

print(len(miss_11))

print(sorted(miss_11))

df.drop(miss_11, axis = 1, inplace = True)

df.head()

#Remove constant features

def find_constant_features(dataFrame):
  const_features = []
  for column in list(dataFrame.columns):
    if dataFrame[column].unique().size < 2:
      const_features.append(column)
  return const_features

const_features = find_constant_features(df)

const_features

df.shape

#Remove duplicate rows

df.drop_duplicates(inplace = True)

df.shape

#Remove duplicate columns

def duplicate_columns(frame):
  groups = frame.columns.to_series().groupby(frame.dtypes).groups
  dups = []

  for t, v in groups.items():

    cs = frame[v].columns
    vs = frame[v]
    lcs = len(cs)

    for i in range(lcs):
      ia = vs.iloc[:,i].values
      for j in range(i+1, lcs):
        ja = vs.iloc[:,j].values
        if np.array_equal(ia, ja):
          dups.append(cs[i])
          break

  return dups

duplicate_cols = duplicate_columns(df)

duplicate_cols







!pip install --user --upgrade scikit-learn

!whoami

import sys
sys.path.insert(0,"/gpfs/fs01/user/root/.local/lib/python2.7/site-packages")

import sklearn
sklearn.__version__

from sklearn.impute import SimpleImputer 
imputer = SimpleImputer(missing_values = "NaN", strategy = "mean")

# Split data into training and testing sets
features = [
'id',
'hip',
'hd',
'ra',
'dec',
'dist',
'pmra',
'pmdec',
'rv',
'mag',
'absmag',
'spect',
'ci',
'x',
'y',
'z',
'vx',
'vy',
'vz',
'rarad',
'decrad',
'pmrarad',
'pmdecrad',
'con',
'comp',
'comp_primary',
'lum',
'var_min',
'var_max',
]

#'Last Updated', 

X = df[features]
y = df['Value']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state = 25)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)


# Look at the closest neighbors
n_size = None
n_best = None
max_acc = 0
for n_size in range(1, 30):
    print("If n is", n_size)
    model = KNeighborsRegressor(n_neighbors=n_size)
    # Calculate the mean accuracy of the KNN model
    model.fit(X_train, y_train)
    accuracy = model.score(X_test,y_test)
    if(max_acc < accuracy):
        max_acc = accuracy
        n_best = n_size
    print('Accuracy: ' + str(np.round(accuracy*100, 2)) + '%')

print("If n is", n_best)
model = KNeighborsRegressor(n_neighbors=n_best)
# Calculate the mean accuracy of the KNN model
model.fit(X_train, y_train)
accuracy = model.score(X_test,y_test)
print('Accuracy: ' + str(np.round(accuracy*100, 2)) + '%')